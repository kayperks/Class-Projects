{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1) Introduction\nThis notebook was created as an assignment for an introductory R Analytics course. I hope this may be useful for others learning R like myself. As an fyi, this notbook will take approximately 4.15 hours to complete, and the submission ranked 1718 on the Leaderboard once submitted. Every hour, make sure to touch the notebook as it runs, to not time it out. \n\nPlease note, if you wish to run this, please comment out or delete every section except section #6 for the Submission file. \n\nTo look up the documentation on a function, use a question mark then the function in R.  example:   ?fread"},{"metadata":{},"cell_type":"markdown","source":"## 2) Preparations"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Display stats on free memory\ngc()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set work directory \n## setwd('/Users/xxx/xxx/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Load Libraries\nsuppressMessages({\n   library(data.table)     # frame data structure\n   library(vroom)          # reads rectangular data\n   library(tidyverse)      # collection of open source R packages\n   library(RcppRoll)       # Provides fast and efficient routines for common rolling / windowed operations\n   library(dplyr)          # grammar of data manipulation\n   library(lubridate)      # Easier to work w/ dates and time\n   library(ggplot2)        # visualization\n   library(patchwork)      # combine separate ggplots into the same graphic\n   library(scales)         # visualisation\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you're working with RStudio, use the below link for instructions on downloading LightGBM - The modelling section below will call the library LightGBM\nhttps://github.com/microsoft/LightGBM/tree/master/R-package#installation\n\nI used this github Online Installer for LightGBM, and followed the approach of downloading Rtools & MinGW for Windows\nhttps://github.com/Laurae2/lgbdl"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales <- fread(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", na.strings=c(\"\", \"NULL\"))  # fread is similar to data.table, but more efficient\nprices <- fread(\"../input/m5-forecasting-accuracy/sell_prices.csv\")                                 \ncal <- fread(\"../input/m5-forecasting-accuracy/calendar.csv\")\n\ncal2 <- read_csv(str_c('../input/m5-forecasting-accuracy/calendar.csv'), col_types = cols())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Free is a function that collects garbage\nfree <- function() invisible(gc())\nfree()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) Understanding the data"},{"metadata":{},"cell_type":"markdown","source":"calendar.csv - Contains information about the dates on which the products are sold.\n\nsales_train_validation.csv - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n\nsample_submission.csv - The correct format for submissions. Reference the Evaluation tab for more info.\n\nsell_prices.csv - Contains information about the price of the products sold per store and date."},{"metadata":{},"cell_type":"markdown","source":"## 4) Overview of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"head(cal)\nhead(prices)\nhead(sales)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Holiday's to predict \ncal[, date  := as.IDate(date)]\nd1 <- cal[d == \"d_1914\", date]\ncal[date >= d1][event_name_1 != \"\"][, c(\"date\",\"weekday\",\"event_name_1\")]\nevent_in_prediction <- cal[date >= d1][event_name_1 != \"\"][, event_name_1]\n\nfree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_days <- names(sales) %>% str_detect(\"d_\") %>% sum()\nds <- ymd(min(cal$date))\nde <-ã€€ds + ddays(n_days-1)\n\ncat(paste0(\"The number of days in sales_train_validation.csv is \", n_days, \".\\n\"))\ncat(paste0(\"The range of days is from \", ds, \" to \", de, \".\"))\n\nfree()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5) Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[, total_sold := apply(sales[, 7:1919], 1, sum)]\n\noptions(repr.plot.width = 25, repr.plot.height = 6)\n\np1 <- sales %>%\n  ggplot(aes(x = store_id, y = total_sold, fill = state_id))+\n  stat_summary(fun=\"sum\", geom=\"bar\", alpha = 0.7) +\n  scale_y_continuous(labels = scales::comma)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))+\n  labs(y = \"Total number of items sold\", \n       title = \"Sales by Store\"\n       )\n\np2 <- sales %>%\n  ggplot(aes(x = dept_id, y = total_sold, fill = state_id))+\n  stat_summary(fun=\"sum\", geom=\"bar\", position = \"dodge\", alpha = 0.7)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))+\n  scale_y_continuous(labels = scales::comma)+\n  labs(y = \"Total number of items sold\", \n       title = \"Sales by Item\"\n       )\n\np3 <- \nsales %>% group_by(dept_id) %>% count(item_id) %>% summarise(n_items = length(item_id))%>%\n  ggplot(aes(x = dept_id, y = n_items, fill = dept_id))+\n  geom_bar(stat = \"identity\", alpha = 0.7)+\n  geom_text(aes(label = n_items), vjust = 1.5, show.legend = F)+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))+\n  theme(legend.position = \"none\")+\n  labs(y = \"Number of items\", \n       title = \"Items by Department\"\n       )\np1+p2+p3  # Uses library patchwork\n\nfree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot time series graph of total sales\nDailySales <- sales[,7:1919]\n\nDailySales <- DailySales %>%\n  summarize_all(sum) %>% \n  gather(key=\"d\", value =\"sales\") %>%\n  left_join(cal2[c(\"d\", \"date\")], by=\"d\") %>%\n  mutate(date=as.Date(date)) %>%\n  mutate(month_name = month(date, label=TRUE), year = year(date)) %>%\n  mutate(month_year = paste(month_name,year,sep=\"_\")) %>%\n  mutate(month_name = month(date, label=TRUE), year = year(date)) %>%\n  mutate(month_year = paste(month_name,year,sep=\"_\")) %>%\n  mutate(wday = wday(date, label=TRUE))\n\n#plot the Time Series\nDailySales %>%\n  ggplot(aes(date, sales)) +\n  geom_line(color = \"red\") +\n  geom_smooth(formula = 'y ~ x', method = \"loess\", color = \"black\", span=1/4) +\n  scale_y_continuous(labels = scales::label_number_si()) + \n  labs(x = 'Month-Year', y = 'Total Sales', title = '2011-2016 Total Sales') +\n  scale_x_date(labels = date_format(\"%m-%Y\"), date_breaks=\"5 months\")\n\nfree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creates a dataframe of monthly sales from 2011-2016 period\nMonthSales <- DailySales %>%\n  group_by(month_name, year, month_year) %>%\n  summarize(sales = sum(sales))\n\nMonthSales %>%\n  filter(month_year != 'Jan_2011', month_year != 'Apr_2016') %>% # Remove months that skew the data\n  ggplot(aes(x=month_name, y=sales)) +\n  geom_boxplot(fill=\"#4271AE\") +\n  scale_y_continuous(labels = scales::label_number_si(accuracy=0.01)) +\n  labs(x = 'Month', y = 'Total Sales', title = 'Total Sales by Month') +\n  theme_bw() \n\nfree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Line Graph\n## Calculating the mean average of sales for the month \nmean_MonthSales <- MonthSales %>%\n  filter(month_year != 'Jan_2011', month_year != 'Apr_2016') %>% # Remove months that skew the data\n  group_by(month_name)  %>%\n  summarize(mean_sales= mean(sales)) \n\nmean_MonthSales %>%\n  ggplot(aes(x=month_name, y=mean_sales, group=1)) +\n  geom_line(size=1, linetype = \"dashed\") +\n  geom_point() +\n  labs(x = 'Month', y = 'Total Sales', title = '2011-2016 Average Sales by Month') \n\nfree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gc()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6) Modeling the data"},{"metadata":{},"cell_type":"markdown","source":"create_dt() function will create a training data table from a wide-format file with leading zeros removed.\n\ncreate_fea() adds lags, rolling features and time variables to the data table."},{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"## Load Libraries\nlibrary(data.table)  # frame data structure\nlibrary(lightgbm)    # gradient boosting framework that uses tree based learning algorithms\n\nset.seed(0)\nh <- 28                         # Forecast horizon\nmax_lags <- 366                 # Number of observations to shift by\ntr_last <- 1913                 # Last training day \nfday <- as.IDate(\"2016-04-25\")  # First day to forecast \n\n#---------------------------\ncat(\"Creating functions...\\n\")\n\nfree <- function() invisible(gc())  # Free is a function that collects garbage\n\ncreate_dt <- function(is_train = TRUE, nrows = Inf) {\n  \n  prices <- fread(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\n  cal <- fread(\"../input/m5-forecasting-accuracy/calendar.csv\")\n  cal[, `:=`(date = as.IDate(date, format=\"%Y-%m-%d\"),  # format date in calendar to yyyy-mm-dd\n             is_weekend = as.integer(weekday %chin% c(\"Saturday\", \"Sunday\")))]   # is_weekend flag - 1 Saturday/ Sunday else 0\n  \n  if (is_train) {\n    dt <- fread(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", nrows = nrows)\n  } else {\n    dt <- fread(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", nrows = nrows,\n                drop = paste0(\"d_\", 1:(tr_last-max_lags)))       # keeps only max_lag days from training set\n    dt[, paste0(\"d_\", (tr_last+1):(tr_last+2*h)) := NA_real_]    # Empty columns for forecasting\n  }\n\n# melt takes data in wide format and stacks a set of columns into a single column of data\n  dt <- melt(dt,\n             measure.vars = patterns(\"^d_\"),\n             variable.name = \"d\",\n             value.name = \"sales\")\n  \n  dt <- dt[cal, `:=`(date = i.date, \n                     is_weekend = i.is_weekend,\n                     wm_yr_wk = i.wm_yr_wk,\n                     event_name_1 = i.event_name_1,\n                     snap_CA = i.snap_CA,\n                     snap_TX = i.snap_TX,\n                     snap_WI = i.snap_WI), on = \"d\"]\n  \n  dt[prices, sell_price := i.sell_price, on = c(\"store_id\", \"item_id\", \"wm_yr_wk\")]\n}\n\ncreate_fea <- function(dt) {\n  \n  lag <- c(7, 28, 29)\n  dt[, (paste0(\"lag_\", lag)) := shift(.SD, lag), .SDcols = \"sales\", by = \"id\"]\n  \n  win <- c(7, 30, 90, 180)\n  dt[, (paste0(\"roll_mean_28_\", win)) := frollmean(lag_28, win, na.rm = TRUE), by = \"id\"]\n  \n  win <- c(28)\n  dt[, (paste0(\"roll_max_28_\", win)) := frollapply(lag_28, win, max), by = \"id\"]\n  dt[, (paste0(\"roll_var_28_\", win)) := frollapply(lag_28, win, var), by = \"id\"]\n  \n  dt[, price_change_1 := sell_price / shift(sell_price) - 1, by = \"id\"]\n  dt[, price_change_365 := sell_price / frollapply(shift(sell_price), 365, max) - 1, by = \"id\"]\n  \n  cols <- c(\"item_id\", \"state_id\", \"dept_id\", \"cat_id\", \"event_name_1\")   \n  dt[, (cols) := lapply(.SD, function(x) as.integer(factor(x))), .SDcols = cols]\n  \n  dt[, `:=`(wday = wday(date),\n            mday = mday(date),\n            week = week(date),\n            month = month(date),\n            quarter = quarter(date),\n            year = year(date),\n            store_id = NULL,\n            d = NULL,\n            wm_yr_wk = NULL)]\n}\n\n#---------------------------\ncat(\"Processing datasets...\\n\")\n\ntr <- create_dt()   # prepare data for training \nfree()              # collect garbage \n\ncreate_fea(tr)\nfree()              # collect garbage \n\ntr <- na.omit(tr)   # removes NA rows \ny <- tr$sales       # only select sales column from traning set \n\nidx <- tr[date <= max(date)-h, which = TRUE]   # indices for training \n\ntr[, c(\"id\", \"sales\", \"date\") := NULL]  # remove id, sales, date columns\nfree()                                  # collect garbage \n\ntr <- data.matrix(tr)  # returns a matrix by converting all variables to numeric \nfree()                 # collect garbage \n\ncats <- c(\"item_id\", \"state_id\", \"dept_id\", \"cat_id\",\n          \"wday\", \"mday\", \"week\", \"month\", \"quarter\", \"year\", \"is_weekend\",\n          \"snap_CA\", \"snap_TX\", \"snap_WI\")   # list categorical features\n\nxtr <- lgb.Dataset(tr[idx, ], label = y[idx], categorical_feature = cats)     # construct lgb dataset \nxval <- lgb.Dataset(tr[-idx, ], label = y[-idx], categorical_feature = cats)  # construct lgb dataset\n\nrm(tr, y, idx)\nfree()            # collect garbage \n\n#---------------------------\ncat(\"Training model...\\n\")\n\n# Poisson traning model, metirc of root mean squared error used \np <- list(objective = \"poisson\",\n          metric =\"rmse\",\n          force_row_wise = TRUE,\n          learning_rate = 0.075,\n          sub_feature = 0.8,\n          sub_row = 0.75,\n          bagging_freq = 1,\n          lambda_l2 = 0.1,\n          nthread = 4)\n\nm_lgb <- lgb.train(params = p,\n                   data = xtr,\n                   nrounds = 2000,\n                   valids = list(valid = xval),\n                   early_stopping_rounds = 400,\n                   eval_freq = 200)\n\ncat(\"Best score:\", m_lgb$best_score, \"at\", m_lgb$best_iter, \"iteration\")                         \nlgb.plot.importance(lgb.importance(m_lgb), 20)\n\nrm(xtr, xval, p)\nfree()\n\n#---------------------------\ncat(\"Forecasting...\\n\") \n\nte <- create_dt(FALSE)\n\nfor (day in as.list(seq(fday, length.out = 2*h, by = \"day\"))){\n  cat(as.character(day), \" \")\n  tst <- te[date >= day - max_lags & date <= day]\n  create_fea(tst)\n  tst <- data.matrix(tst[date == day][, c(\"id\", \"sales\", \"date\") := NULL])\n  te[date == day, sales := predict(m_lgb, tst)]\n}\n\nte[date >= fday\n   ][date >= fday+h, id := sub(\"validation\", \"evaluation\", id)\n     ][, d := paste0(\"F\", 1:28), by = id\n       ][, dcast(.SD, id ~ d, value.var = \"sales\")\n         ][, fwrite(.SD, \"Submission_LBGM.csv\")]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.0","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":4}